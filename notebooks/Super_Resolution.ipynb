{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_JtASV4VSaG"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/binh234/isr/blob/main/notebooks/Super_Resolution.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyRE9kmrs1ot",
        "outputId": "19ca0ed4-bb18-470c-b85e-9e37ebc69e94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'isr'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 72 (delta 18), reused 61 (delta 12), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (72/72), 5.54 MiB | 9.38 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/binh234/isr.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ODrgJnd9tAL6",
        "outputId": "433b3a80-a760-420d-f602-dd60a7aa408b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/isr\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/36/7b/2147339dafe1c4800514c9c21ee4444f8b419ce51dfc7695220a8e0069a6/facexlib-0.3.0-py3-none-any.whl.metadata\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%cd isr\n",
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install --upgrade torchvision\n"
      ],
      "metadata": {
        "id": "h_CMEMxvcmNM",
        "outputId": "cb19a373-27c1-4953-e074-9a04d6789e2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Collecting torch==2.6.0 (from torchvision)\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Collecting triton==3.2.0 (from torch==2.6.0->torchvision)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (2.1.5)\n",
            "Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu124\n",
            "    Uninstalling torchvision-0.20.1+cu124:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cusparselt-cu12-0.6.2 torch-2.6.0 torchvision-0.21.0 triton-3.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen",
                  "torchvision",
                  "triton"
                ]
              },
              "id": "81d86863a3494b508a9922366e635cbf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiQu7AwVtGW5"
      },
      "source": [
        "# Gradio App"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd isr"
      ],
      "metadata": {
        "id": "2E1VbX96fN_Z",
        "outputId": "20a2da81-6109-49cb-9f6c-256fb84e6e1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/isr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "l7O5VbuGfetA",
        "outputId": "a7df28be-bb94-4486-b171-742294b0f909",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py\t   Dockerfile  images\t    LICENSE    __pycache__  requirements.txt  style.css    utils.py\n",
            "config.py  examples    __init__.py  notebooks  README.md    srcnn.py\t      upsample.py  weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "grBrjCAHtHiB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import gradio as gr\n",
        "from isr.utils import get_upsampler, get_face_enhancer\n",
        "\n",
        "\n",
        "def inference(img, task, model_name, scale):\n",
        "    if scale > 4:\n",
        "        scale = 4  # avoid too large scale value\n",
        "    try:\n",
        "        img = cv2.imread(img, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "        h, w = img.shape[0:2]\n",
        "        if h > 3500 or w > 3500:\n",
        "            raise gr.Error(f\"image too large: {w} * {h}\")\n",
        "\n",
        "        if (h < 300 and w < 300) and model_name != \"srcnn\":\n",
        "            img = cv2.resize(img, (w * 2, h * 2), interpolation=cv2.INTER_LANCZOS4)\n",
        "            return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if task == \"face\":\n",
        "            upsample_model_name = \"realesr-general-x4v3\"\n",
        "        else:\n",
        "            upsample_model_name = model_name\n",
        "        upsampler = get_upsampler(upsample_model_name)\n",
        "\n",
        "        if task == \"face\":\n",
        "            face_enhancer = get_face_enhancer(model_name, scale, upsampler)\n",
        "        else:\n",
        "            face_enhancer = None\n",
        "\n",
        "        try:\n",
        "            if face_enhancer is not None:\n",
        "                _, _, output = face_enhancer.enhance(\n",
        "                    img, has_aligned=False, only_center_face=False, paste_back=True\n",
        "                )\n",
        "            else:\n",
        "                output, _ = upsampler.enhance(img, outscale=scale)\n",
        "        except RuntimeError as error:\n",
        "            raise gr.Error(error)\n",
        "\n",
        "        output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
        "        return output\n",
        "    except Exception as error:\n",
        "        raise gr.Error(f\"global exception: {error}\")\n",
        "\n",
        "\n",
        "def on_task_change(task):\n",
        "    if task == \"general\":\n",
        "        return gr.Dropdown.update(\n",
        "            choices=[\n",
        "                \"srcnn\",\n",
        "                \"RealESRGAN_x2plus\",\n",
        "                \"RealESRGAN_x4plus\",\n",
        "                \"RealESRNet_x4plus\",\n",
        "                \"realesr-general-x4v3\",\n",
        "            ],\n",
        "            value=\"realesr-general-x4v3\",\n",
        "        )\n",
        "    elif task == \"face\":\n",
        "        return gr.Dropdown.update(\n",
        "            choices=[\"GFPGANv1.3\", \"GFPGANv1.4\", \"RestoreFormer\"], value=\"GFPGANv1.4\"\n",
        "        )\n",
        "    elif task == \"anime\":\n",
        "        return gr.Dropdown.update(\n",
        "            choices=[\"srcnn\", \"RealESRGAN_x4plus_anime_6B\", \"realesr-animevideov3\"],\n",
        "            value=\"RealESRGAN_x4plus_anime_6B\",\n",
        "        )\n",
        "\n",
        "\n",
        "title = \"ISR: General Image Super Resolution\"\n",
        "\n",
        "with gr.Blocks(css=\"style.css\", title=title) as demo:\n",
        "    with gr.Row(elem_classes=[\"container\"]):\n",
        "        with gr.Column(scale=2):\n",
        "            input_image = gr.Image(type=\"filepath\", label=\"Input\")\n",
        "            # with gr.Row():\n",
        "            task = gr.Dropdown(\n",
        "                [\"general\", \"face\", \"anime\"],\n",
        "                type=\"value\",\n",
        "                value=\"general\",\n",
        "                label=\"task\",\n",
        "            )\n",
        "            model_name = gr.Dropdown(\n",
        "                [\n",
        "                    \"srcnn\",\n",
        "                    \"RealESRGAN_x2plus\",\n",
        "                    \"RealESRGAN_x4plus\",\n",
        "                    \"RealESRNet_x4plus\",\n",
        "                    \"realesr-general-x4v3\",\n",
        "                ],\n",
        "                type=\"value\",\n",
        "                value=\"realesr-general-x4v3\",\n",
        "                label=\"model\",\n",
        "            )\n",
        "            scale = gr.Slider(\n",
        "                minimum=1.5,\n",
        "                maximum=4,\n",
        "                value=2,\n",
        "                step=0.5,\n",
        "                label=\"Scale factor\",\n",
        "                info=\"Scaling factor\",\n",
        "            )\n",
        "            run_btn = gr.Button(value=\"Submit\")\n",
        "\n",
        "        with gr.Column(scale=3):\n",
        "            output_image = gr.Image(type=\"numpy\", label=\"Output image\")\n",
        "\n",
        "    with gr.Row(elem_classes=[\"container\"]):\n",
        "        gr.Examples(\n",
        "            [\n",
        "                [\"examples/landscape.jpg\", \"general\", 2],\n",
        "                [\"examples/cat.jpg\", \"general\", 2],\n",
        "                [\"examples/cat2.jpg\", \"face\", 2],\n",
        "                [\"examples/AI-generate.png\", \"face\", 2],\n",
        "                [\"examples/Blake_Lively.png\", \"face\", 2],\n",
        "                [\"examples/old_image.jpg\", \"face\", 2],\n",
        "                [\"examples/naruto.png\", \"anime\", 2],\n",
        "                [\"examples/luffy2.jpg\", \"anime\", 2],\n",
        "            ],\n",
        "            [input_image, task, scale],\n",
        "        )\n",
        "\n",
        "    run_btn.click(inference, [input_image, task, model_name, scale], [output_image])\n",
        "    task.change(on_task_change, [task], [model_name])\n",
        "\n",
        "# def greet(name):\n",
        "#     return f\"Hello, {name}!\"\n",
        "# demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
        "\n",
        "# demo.queue().launch(share=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}